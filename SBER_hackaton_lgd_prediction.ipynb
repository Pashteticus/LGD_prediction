{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7RHAvNzXr5R"
      },
      "source": [
        "# Решение задачи предсказания LGD-рисков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfkA6dJ_Xso8"
      },
      "source": [
        "# Загружаем данные и устанавливаем нужные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiYoYysUX6uG"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install lightgbm\n",
        "!pip install xgboost\n",
        "!pip install -U dask    # после установки рекомендую перезагрузить ядро\n",
        "!pip install featuretools\n",
        "!pip install evalml\n",
        "!pip install mljar-supervised\n",
        "!pip install requests\n",
        "!pip install tabulate\n",
        "!pip install \"colorama>=0.3.8\"\n",
        "!pip install future\n",
        "!pip uninstall h2o\n",
        "!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15aDxzgmYByy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "from math import log\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from catboost import *\n",
        "from xgboost import XGBRegressor, XGBRFRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from supervised.automl import AutoML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from sklearn.externals.six import StringIO\n",
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "from h2o.sklearn import H2OAutoMLRegressor\n",
        "\n",
        "h2o.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxerCZufYS5U"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/BKHV/risk_models/master/data/LGD-data-train.csv\n",
        "!wget https://raw.githubusercontent.com/BKHV/risk_models/master/data/LGD-data-test.csv\n",
        "!wget https://raw.githubusercontent.com/BKHV/risk_models/master/data/PD-data-desc.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO0ppVCGYURx"
      },
      "source": [
        "train_df = pd.read_csv('LGD-data-train.csv', sep=';')\n",
        "test_df = pd.read_csv('LGD-data-test.csv', sep=';')\n",
        "desc_df = pd.read_csv('PD-data-desc.csv', sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maTgagR_Ydzi"
      },
      "source": [
        "desc_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQnR8dAgYfaC"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB87Qqc5Xs7R"
      },
      "source": [
        "# Пишем полезные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxBrBj8mYk6S"
      },
      "source": [
        "def add_new_features(df, df1):\n",
        "    for d in [df, df1]:\n",
        "        d['ead'] = d['ab_accounts_payable'] + d['ab_other_borrowings'] + d['ab_borrowed_capital'] + d['ab_accounts_receivable']\n",
        "        d['prob_recovery'] = d['ab_inventory'] + d['ab_own_capital']\n",
        "        d['ub'] = d['ead'] - d['ab_inventory'] - d['ab_own_capital']\n",
        "    return (df, df1)\n",
        "\n",
        "def get_two_data_frames(data):\n",
        "    d1, d2 = [], []\n",
        "    cols = data.columns\n",
        "    for i in range(len(data)):\n",
        "        if data.iloc[i].isna().sum() == 0:\n",
        "            d1.append(data.iloc[i].tolist())\n",
        "            d2.append(data.iloc[i].tolist())\n",
        "        else:\n",
        "            d2.append(data.iloc[i].tolist())\n",
        "    d1, d2 = pd.DataFrame(d1, columns=cols), pd.DataFrame(d2, columns=cols)\n",
        "    del_cols = []\n",
        "    for x in d2:\n",
        "        if d2[x].isna().sum() != 0:\n",
        "            del_cols += [x]\n",
        "    d2 = d2.drop(columns=del_cols)\n",
        "    return (d1, d2)\n",
        "\n",
        "def make_predict(model, test, name):\n",
        "    preds = model.predict(test)\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] > 1:\n",
        "            preds[i] = 1\n",
        "        if preds[i] < 0:\n",
        "            preds[i] = 0\n",
        "    sumbit_df = test[['record_id']].copy()\n",
        "    sumbit_df['predict'] = preds\n",
        "    sumbit_df.rename({'record_id':'id'},axis=1,inplace=True)\n",
        "    sumbit_df.to_csv(name, index=False)\n",
        "\n",
        "def make_two_models_predict(model_0, model_24, test, name):\n",
        "    res = test['record_id']\n",
        "    preds = []\n",
        "    test_0, test_24 = get_two_data_frames(test)\n",
        "    preds_0 = np.array(model_0.predict(test_0))\n",
        "    preds_24 = np.array(model_24.predict(test_24))\n",
        "    for i in range(len(preds_0)):\n",
        "        if preds_0[i] > 1:\n",
        "            preds_0[i] = 1\n",
        "        if preds_0[i] < 0:\n",
        "            preds_0[i] = 0\n",
        "    for i in range(len(preds_24)):\n",
        "        if preds_24[i] > 1:\n",
        "            preds_24[i] = 1\n",
        "        if preds_24[i] < 0:\n",
        "            preds_24[i] = 0\n",
        "    preds_0 = pd.DataFrame(list(zip(test_0['record_id'].tolist(), preds_0)), columns=['id', 'predict'])\n",
        "    preds_24 = pd.DataFrame(list(zip(test_24['record_id'].tolist(), preds_24)), columns=['id', 'predict'])\n",
        "    \n",
        "    res = pd.concat([preds_0, preds_24])\n",
        "    res.to_csv(name, index=False)\n",
        "\n",
        "def make_sber_predict(model, test, name):\n",
        "    preds = model.predict(test).data[:, 0]\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] > 1:\n",
        "            preds[i] = 1\n",
        "        if preds[i] < 0:\n",
        "            preds[i] = 0\n",
        "    sumbit_df = test[['record_id']].copy()\n",
        "    sumbit_df['predict'] = preds\n",
        "    sumbit_df.rename({'record_id':'id'},axis=1,inplace=True)\n",
        "    sumbit_df.to_csv(name, index=False)\n",
        "\n",
        "def make_predict_h2o(model, test_df, name):\n",
        "    preds = model.predict(test_df)\n",
        "    preds = h2o.as_list(preds)\n",
        "    for i in range(len(preds['predict'])):\n",
        "        if preds['predict'][i] > 1:\n",
        "            preds['predict'][i] = 1\n",
        "        if preds['predict'][i] < 0:\n",
        "            preds['predict'][i] = 0\n",
        "    preds['id'] = h2o.as_list(test_df)['record_id']\n",
        "    preds = pd.DataFrame(list(zip(preds['id'].tolist(), preds['predict'].tolist())), columns=['id', 'predict'])\n",
        "    preds.to_csv(name, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDqWgNiAXtwu"
      },
      "source": [
        "# Готовим данные для обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjF2oEyXYx2t"
      },
      "source": [
        "cat_features, cat_test = add_new_features(train_df[[x for x in train_df.columns if x != 'lgd']], test_df[[x for x in test_df.columns if x != 'lgd']])\n",
        "# cat_features, cat_test = train_df[[x for x in train_df.columns if x != 'lgd']], test_df[[x for x in test_df.columns if x != 'lgd']]\n",
        "cat_target = train_df[['lgd']]\n",
        "cat_columns = [x for x in train_df.columns if train_df[x].dtype == 'object']\n",
        "'''for x in cat_features:\n",
        "    if 'cnt' in x or 'flg' in x:\n",
        "        cat_features[x] = cat_features[x].astype('object')\n",
        "for x in cat_test:\n",
        "    if 'cnt' in x or 'flg' in x:\n",
        "        cat_test[x] = cat_test[x].astype('object')'''\n",
        "cat_columns = [x for x in train_df.columns if train_df[x].dtype == 'object']\n",
        "\n",
        "features = train_df[[x for x in train_df.columns if x != 'lgd']]\n",
        "target = train_df[['lgd']]\n",
        "test = test_df[[x for x in test_df.columns if x != 'lgd' and test_df[x].dtype != 'object']]\n",
        "\n",
        "\n",
        "features_na = train_df[[x for x in train_df.columns if x != 'lgd' and train_df[x].dtype != 'object' and train_df[x].isna().sum() == 0]]\n",
        "target_na = train_df[['lgd']]\n",
        "test_na = test_df[[x for x in test_df.columns if x != 'lgd' and test_df[x].dtype != 'object' and test_df[x].isna().sum() == 0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_TOJrWNY3VT"
      },
      "source": [
        "# Различные решения данной задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchdhJFaY7DD"
      },
      "source": [
        "## Feature tools + Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BHhzGn7ZBZ3"
      },
      "source": [
        "df = cat_features.copy()\n",
        "df = df.append(cat_test, ignore_index=True)\n",
        "for x in df:\n",
        "    if df[x].isna().sum() != 0 and df[x].dtype!='object':\n",
        "        df[x].fillna(0, inplace=True)\n",
        "    elif df[x].dtype=='object' and df[x].isna().sum()!=0:\n",
        "        df[x].fillna('Unknown', inplace=True)\n",
        "df['id'] = [i for i in range(len(df['record_id']))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1vgKCrFZETD"
      },
      "source": [
        "es = ft.EntitySet(id = 'sber')\n",
        "es = es.entity_from_dataframe(entity_id = 'lgd', dataframe = df, index = 'id')\n",
        "es.normalize_entity(base_entity_id='lgd', new_entity_id='lgd_adv_train', index = 'record_id',\n",
        "additional_variables = [x for x in df.columns if 'ar_' in x or 'ab_' in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjlvgX_yZFeS"
      },
      "source": [
        "feature_matrix, feature_names = ft.dfs(entityset=es,\n",
        "    target_entity = 'lgd',\n",
        "    max_depth = 5,\n",
        "    verbose = 1,\n",
        "    n_jobs = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb4OaN_SZHAR"
      },
      "source": [
        "tr, ts = feature_matrix[:len(cat_features)], feature_matrix[len(cat_features):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcFyYGidZKTe"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(tr, cat_target, test_size=0.1)\n",
        "model = CatBoostRegressor(cat_features=cat_columns, \n",
        "                          random_seed=337, \n",
        "                          loss_function='MAE', \n",
        "                          l2_leaf_reg=2.8, \n",
        "                          nan_mode='Min',\n",
        "                          score_function='L2',\n",
        "                          n_estimators=618,\n",
        "                          max_depth=6,\n",
        "                          random_strength=1.5,\n",
        "                          boosting_type='Plain',\n",
        "                          rsm=1,\n",
        "                          )\n",
        "model.fit(X_train, y_train)\n",
        "mean_absolute_error(y_val, model.predict(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdPi2XH5ZfrE"
      },
      "source": [
        "make_predict(model, ts, 'feature_tools_catboost.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST5AhL2SZ-6W"
      },
      "source": [
        "MAE: 0.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LX1zFtPZcI3"
      },
      "source": [
        "## Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhr4cDGzZ4aR"
      },
      "source": [
        "model = CatBoostRegressor(cat_features=cat_columns, \n",
        "                          random_seed=337, \n",
        "                          loss_function='MAE', \n",
        "                          l2_leaf_reg=2.8, \n",
        "                          nan_mode='Min',\n",
        "                          score_function='L2',\n",
        "                          n_estimators=618,\n",
        "                          max_depth=6,\n",
        "                          random_strength=1.5,\n",
        "                          boosting_type='Plain',\n",
        "                          rsm=1,\n",
        "                          )\n",
        "model.fit(cat_features, target)\n",
        "mean_absolute_error(target, model.predict(cat_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pxk85LiZ8Mr"
      },
      "source": [
        "make_predict(model, cat_test, 'catboost')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7I5ZxwZaBjx"
      },
      "source": [
        "MAE: 0.0974"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE2F1rxtaEwB"
      },
      "source": [
        "## Catboost with feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5cMvk4xaHke"
      },
      "source": [
        "fi = model.get_feature_importance(prettified=True)\n",
        "good_cols = fi['Feature Id'][fi['Importances'] > 1].to_list()\n",
        "if 'record_id' not in good_cols:\n",
        "    good_cols.append('record_id')\n",
        "good_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8R8O8TqaMcK"
      },
      "source": [
        "new_model = CatBoostRegressor(cat_features=[x for x in cat_features[good_cols] if cat_features[good_cols][x].dtype == 'object'], \n",
        "                          random_seed=337, \n",
        "                          loss_function='MAE', \n",
        "                          l2_leaf_reg=2.8, \n",
        "                          nan_mode='Min',\n",
        "                          score_function='L2',\n",
        "                          n_estimators=818,\n",
        "                          max_depth=6,\n",
        "                          random_strength=1.5,\n",
        "                          boosting_type='Plain',\n",
        "                          rsm=1\n",
        "                          )\n",
        "new_model.fit(cat_features[good_cols], target)\n",
        "mean_absolute_error(target, new_model.predict(cat_features[good_cols]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Lf6r7gaNr6"
      },
      "source": [
        "make_predict(new_model, cat_test[good_cols], 'catboost_fs.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuYezdwAaToZ"
      },
      "source": [
        "MAE: 0.0981"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9SBJVROaWCy"
      },
      "source": [
        "## Grid search on catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybOAEmHaVVX"
      },
      "source": [
        "model = CatBoostRegressor(cat_features=cat_columns, verbose=500, loss_function='MAE', eval_metric='MAE', random_seed=337)\n",
        "params = {'n_estimators': [700, 800, 900, 1000],\n",
        "          'l2_leaf_reg': [2.6, 2.7, 2.8, 2.9, 3, 3.1],\n",
        "          'depth': [4,5,6,7],\n",
        "          #'learning_rate': [0.1, 0.05, 0.025, 0.01],\n",
        "          'score_function': ['Cosine', 'L2']}\n",
        "grid_search_result = model.grid_search(params, \n",
        "                                       X=cat_features, \n",
        "                                       y=cat_target, \n",
        "                                       plot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytgjk7ryak-y"
      },
      "source": [
        "make_predict(model, cat_test, 'gs_catboost.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjMwyeftbQP9"
      },
      "source": [
        "MAE: 0.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ru0UWcEbFrB"
      },
      "source": [
        "## Two catboosts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGJNN1VhbH4O"
      },
      "source": [
        "train_0, train_24 = get_two_data_frames(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Qac7BLbK9y"
      },
      "source": [
        "model_0 = CatBoostRegressor(cat_features=cat_columns, \n",
        "                          random_seed=337, \n",
        "                          loss_function='MAE', \n",
        "                          l2_leaf_reg=2.8, \n",
        "                          nan_mode='Min',\n",
        "                          score_function='L2',\n",
        "                          n_estimators=618,\n",
        "                          max_depth=6,\n",
        "                          random_strength=1.5,\n",
        "                          boosting_type='Plain',\n",
        "                          rsm=1)\n",
        "model_24 = CatBoostRegressor(cat_features=cat_columns, \n",
        "                          random_seed=337, \n",
        "                          loss_function='MAE', \n",
        "                          l2_leaf_reg=2.8, \n",
        "                          nan_mode='Min',\n",
        "                          score_function='L2',\n",
        "                          n_estimators=618,\n",
        "                          max_depth=6,\n",
        "                          random_strength=1.5,\n",
        "                          boosting_type='Plain',\n",
        "                          rsm=1)\n",
        "model_0.fit(train_0[[x for x in train_0 if x != 'lgd']], train_0['lgd'])\n",
        "model_24.fit(train_24[[x for x in train_24 if x != 'lgd']], train_24['lgd'])\n",
        "mean_absolute_error(train_0['lgd'], model_0.predict(train_0[[x for x in train_0 if x != 'lgd']])), mean_absolute_error(train_24['lgd'], model_24.predict(train_24[[x for x in train_24 if x != 'lgd']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSc8GvsobNoU"
      },
      "source": [
        "make_two_models_predict(model_0, model_24, test_df, 'great.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QKXXfh-bObX"
      },
      "source": [
        "MAE: 0.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXmLxXP-avE9"
      },
      "source": [
        "# AutoML решения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG-IcXW9a0HG"
      },
      "source": [
        "## LightAutoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf7mrKX9a164"
      },
      "source": [
        "sber_train = cat_features.copy()\n",
        "sber_train['lgd'] = cat_target['lgd']\n",
        "sber_test = cat_test.copy()\n",
        "train, val = train_test_split(sber_train, test_size=0.2)\n",
        "task = Task('reg', loss = 'mae', metric = 'mae')\n",
        "roles = {\n",
        "    'target': 'lgd',\n",
        "    'drop': ['record_id'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXxubsaCa6SZ"
      },
      "source": [
        "automl = TabularAutoML(task = task, \n",
        "                       timeout = 300,\n",
        "                       cpu_limit = 1,\n",
        "                       reader_params = {'n_jobs': 1, 'cv': 5, 'random_state': 337},\n",
        "                      verbose = 1)\n",
        "preds = automl.fit_predict(train, roles = roles)\n",
        "mean_absolute_error(val['lgd'], automl.predict(val[[x for x in val if x != 'lgd']]).data[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2T0A3PrbATU"
      },
      "source": [
        "make_sber_predict(automl, sber_test, 'sber.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7wB-KLFbSMW"
      },
      "source": [
        "MAE: 0.0993"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr9rs9mEbX3O"
      },
      "source": [
        "## MLJAR - supervised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KUA7UINbh4-"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cat_features, cat_target, test_size=0.25\n",
        ")\n",
        "\n",
        "automl = AutoML(random_state=337,\n",
        "                eval_metric='mae',\n",
        "                mode='Compete',\n",
        "                ml_task='regression',\n",
        "                hill_climbing_steps=3,\n",
        "                algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
        "                top_models_to_improve=4,\n",
        "                kmeans_features=True\n",
        "                )\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "predictions = automl.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ8GrgutbmpO"
      },
      "source": [
        "mean_absolute_error(y_val, automl.predict(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpegMC3bnov"
      },
      "source": [
        "make_predict(automl, cat_test, 'mljar.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6MSl6KNbp19"
      },
      "source": [
        "MAE: 0.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phtnG6fRbsCt"
      },
      "source": [
        "## H2O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW6acbyxbxdd"
      },
      "source": [
        "train_df = h2o.import_file('LGD-data-train.csv')\n",
        "test_df = h2o.import_file('LGD-data-test.csv')\n",
        "desc_df = pd.read_csv('PD-data-desc.csv', sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEMD4WZacFrS"
      },
      "source": [
        "x = train_df.columns\n",
        "y = \"lgd\"\n",
        "x.remove(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJDSskJJcG8W"
      },
      "source": [
        "aml = H2OAutoML(max_models=10, seed=337)\n",
        "aml.fit(train_df[x], train_df[y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvq7Te5YcLTD"
      },
      "source": [
        "aml.leaderboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl8gzJ6ScLHh"
      },
      "source": [
        "make_predict_h2o(aml, test_df, 'h2o.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Q5d52QcVW8"
      },
      "source": [
        "MAE: 0.113"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR5uRo5YcWrj"
      },
      "source": [
        "## Autosklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tar_CDQcaNX"
      },
      "source": [
        "features = train_df[[x for x in train_df.columns if x != 'lgd' and train_df[x].dtype != 'object']]\n",
        "cat_columns = [x for x in train_df if train_df[x].dtype == 'object']\n",
        "cat_features = train_df[[x for x in train_df.columns if x != 'lgd']]\n",
        "lin_features = train_df.dropna()[[x for x in train_df.columns if x != 'lgd' and train_df[x].dtype != 'object']]\n",
        "lin_target = train_df.dropna()[['lgd']]\n",
        "target = train_df[['lgd']]\n",
        "test = test_df[[x for x in test_df.columns if x != 'lgd' and test_df[x].dtype != 'object']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hWVijPlcboB"
      },
      "source": [
        "automl = autosklearn.regression.AutoSklearnRegressor(\n",
        "                            time_left_for_this_task=600,\n",
        "                            per_run_time_limit=10,\n",
        "                            tmp_folder='/tmp/autosklearn_regression_example_tmp1',\n",
        "                            output_folder='/tmp/autosklearn_regression_example_out1',\n",
        "                            )\n",
        "automl.fit(features, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLfZrqgAcfAj"
      },
      "source": [
        "mean_absolute_error(target, automl.predict(features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAtmxqa0cjDN"
      },
      "source": [
        "make_predict(automl, test, 'autosklearn.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygzu0yjics0L"
      },
      "source": [
        "MAE: 0.17"
      ]
    }
  ]
}